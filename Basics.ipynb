{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLcjwGpQinceQQt489fxIH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neermita18/Deep-Learning/blob/main/Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backpropagation with user functions\n"
      ],
      "metadata": {
        "id": "ls2wImbWDsZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gcb9vkvv_Ugu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X= torch.rand(2,3)\n",
        "Y= torch.rand(2,1)\n",
        "W= torch.zeros(3,1)"
      ],
      "metadata": {
        "id": "lYLkc9IUCEyw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "  return torch.from_numpy(np.dot(x,W))\n",
        "def loss(y,y_pred):\n",
        "  return ((y_pred-y)**2).mean()\n",
        "def gradient(x,y,y_pred):\n",
        "  return np.dot(2*x.T,y_pred-y).mean()"
      ],
      "metadata": {
        "id": "nQHAShdYDrmT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Basic Backprop and Loss"
      ],
      "metadata": {
        "id": "7GX_utuAKWHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.01\n",
        "i=10\n",
        "for epoch in range(i):\n",
        "  y_pred=forward(X)\n",
        "  l=loss(Y,y_pred)\n",
        "  dw=gradient(X,Y,y_pred)\n",
        "  W-=lr*dw\n",
        "  print(f\"Loss: {l}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Q4Kk_pEomh",
        "outputId": "4d0c2d1c-913d-490a-dfbe-615b48d8b329"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2717524766921997\n",
            "\n",
            "Loss: 0.2552673816680908\n",
            "\n",
            "Loss: 0.24013637006282806\n",
            "\n",
            "Loss: 0.22624818980693817\n",
            "\n",
            "Loss: 0.21350081264972687\n",
            "\n",
            "Loss: 0.20180046558380127\n",
            "\n",
            "Loss: 0.19106118381023407\n",
            "\n",
            "Loss: 0.18120403587818146\n",
            "\n",
            "Loss: 0.17215652763843536\n",
            "\n",
            "Loss: 0.16385219991207123\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VwP4rV1AKZfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backprop with Autograd"
      ],
      "metadata": {
        "id": "iI0sPn5TTK2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=torch.rand(2,3, dtype=torch.float32)\n",
        "Y=torch.rand(2,1,dtype=torch.float32)\n",
        "W=torch.zeros(3,1,dtype=torch.float32,requires_grad=True)"
      ],
      "metadata": {
        "id": "VXDQFZzaE4Uu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "  return torch.matmul(x,W)\n",
        "def loss(y,y_pred):\n",
        "  return ((y_pred-y)**2).mean()\n",
        "def gradient(x,y,y_pred):\n",
        "  return np.dot(2*x.T,y_pred-y).mean()"
      ],
      "metadata": {
        "id": "mL77oCgUTY9c"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=500\n",
        "lr=0.01\n",
        "for epoch in range(epochs):\n",
        "  y_pred=forward(X)\n",
        "  l=loss(Y,y_pred)\n",
        "  l.backward()\n",
        "  with torch.no_grad():\n",
        "    W-=lr*W.grad #manual updation of weights\n",
        "  W.grad.zero_()\n",
        "  if epoch%10==0:\n",
        "    print(f\"Loss: {l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cKd8fKrTZl9",
        "outputId": "a7d4d1f6-97c6-48ee-f3d9-45d9d7f2e91a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.36088237166404724\n",
            "Loss: 0.2830577790737152\n",
            "Loss: 0.22662831842899323\n",
            "Loss: 0.18559259176254272\n",
            "Loss: 0.15563520789146423\n",
            "Loss: 0.13365286588668823\n",
            "Loss: 0.11741384118795395\n",
            "Loss: 0.10531329363584518\n",
            "Loss: 0.0961969643831253\n",
            "Loss: 0.08923481404781342\n",
            "Loss: 0.08382968604564667\n",
            "Loss: 0.07955212891101837\n",
            "Loss: 0.07609312236309052\n",
            "Loss: 0.07323035597801208\n",
            "Loss: 0.07080376148223877\n",
            "Loss: 0.06869816780090332\n",
            "Loss: 0.06683050096035004\n",
            "Loss: 0.0651409775018692\n",
            "Loss: 0.06358647346496582\n",
            "Loss: 0.06213575601577759\n",
            "Loss: 0.06076633930206299\n",
            "Loss: 0.059461817145347595\n",
            "Loss: 0.0582103431224823\n",
            "Loss: 0.05700325220823288\n",
            "Loss: 0.055834174156188965\n",
            "Loss: 0.05469841510057449\n",
            "Loss: 0.05359248071908951\n",
            "Loss: 0.052513740956783295\n",
            "Loss: 0.051460184156894684\n",
            "Loss: 0.05043027177453041\n",
            "Loss: 0.04942277818918228\n",
            "Loss: 0.048436716198921204\n",
            "Loss: 0.047471240162849426\n",
            "Loss: 0.046525683254003525\n",
            "Loss: 0.045599453151226044\n",
            "Loss: 0.044691987335681915\n",
            "Loss: 0.04380284249782562\n",
            "Loss: 0.042931556701660156\n",
            "Loss: 0.042077742516994476\n",
            "Loss: 0.04124099016189575\n",
            "Loss: 0.040420956909656525\n",
            "Loss: 0.03961727023124695\n",
            "Loss: 0.03882959485054016\n",
            "Loss: 0.038057614117860794\n",
            "Loss: 0.03730098158121109\n",
            "Loss: 0.03655943274497986\n",
            "Loss: 0.035832617431879044\n",
            "Loss: 0.03512025251984596\n",
            "Loss: 0.03442206233739853\n",
            "Loss: 0.033737752586603165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch functions"
      ],
      "metadata": {
        "id": "u17yYdfzdTLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "I90d8HY0VLf9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=torch.rand(2,3, dtype=torch.float32)\n",
        "Y=torch.rand(2,1,dtype=torch.float32)\n",
        "W=torch.zeros(3,1,dtype=torch.float32,requires_grad=True)"
      ],
      "metadata": {
        "id": "BFUF1S44dWq5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "  return torch.matmul(x,W)\n"
      ],
      "metadata": {
        "id": "Vdghn51PdeRe"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss= nn.MSELoss()\n",
        "optimizer= torch.optim.SGD([W],lr=0.01)"
      ],
      "metadata": {
        "id": "aY1QK2c1dofB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=100\n",
        "for epoch in range(epochs):\n",
        "  y_pred=forward(X)\n",
        "  l=loss(Y,y_pred)\n",
        "  l.backward()\n",
        "  optimizer.step() #automatic update weights\n",
        "  optimizer.zero_grad()\n",
        "  print(f\"Epoch: {epoch}, Loss: {l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWRi28jnd1Ao",
        "outputId": "25d191da-8444-4ae6-9a5a-3473a663c791"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.28995728492736816\n",
            "Epoch: 1, Loss: 0.2840479910373688\n",
            "Epoch: 2, Loss: 0.2782595157623291\n",
            "Epoch: 3, Loss: 0.27258944511413574\n",
            "Epoch: 4, Loss: 0.2670353353023529\n",
            "Epoch: 5, Loss: 0.2615947723388672\n",
            "Epoch: 6, Loss: 0.2562655210494995\n",
            "Epoch: 7, Loss: 0.25104519724845886\n",
            "Epoch: 8, Loss: 0.24593167006969452\n",
            "Epoch: 9, Loss: 0.2409226894378662\n",
            "Epoch: 10, Loss: 0.2360161542892456\n",
            "Epoch: 11, Loss: 0.23120993375778198\n",
            "Epoch: 12, Loss: 0.22650201618671417\n",
            "Epoch: 13, Loss: 0.22189034521579742\n",
            "Epoch: 14, Loss: 0.21737302839756012\n",
            "Epoch: 15, Loss: 0.2129480391740799\n",
            "Epoch: 16, Loss: 0.2086135298013687\n",
            "Epoch: 17, Loss: 0.20436766743659973\n",
            "Epoch: 18, Loss: 0.2002086043357849\n",
            "Epoch: 19, Loss: 0.19613458216190338\n",
            "Epoch: 20, Loss: 0.19214388728141785\n",
            "Epoch: 21, Loss: 0.18823476135730743\n",
            "Epoch: 22, Loss: 0.1844055950641632\n",
            "Epoch: 23, Loss: 0.18065470457077026\n",
            "Epoch: 24, Loss: 0.17698049545288086\n",
            "Epoch: 25, Loss: 0.17338141798973083\n",
            "Epoch: 26, Loss: 0.16985593736171722\n",
            "Epoch: 27, Loss: 0.16640251874923706\n",
            "Epoch: 28, Loss: 0.16301971673965454\n",
            "Epoch: 29, Loss: 0.15970605611801147\n",
            "Epoch: 30, Loss: 0.15646015107631683\n",
            "Epoch: 31, Loss: 0.1532806009054184\n",
            "Epoch: 32, Loss: 0.15016604959964752\n",
            "Epoch: 33, Loss: 0.14711518585681915\n",
            "Epoch: 34, Loss: 0.14412668347358704\n",
            "Epoch: 35, Loss: 0.1411992609500885\n",
            "Epoch: 36, Loss: 0.13833168148994446\n",
            "Epoch: 37, Loss: 0.1355227380990982\n",
            "Epoch: 38, Loss: 0.13277119398117065\n",
            "Epoch: 39, Loss: 0.13007590174674988\n",
            "Epoch: 40, Loss: 0.12743571400642395\n",
            "Epoch: 41, Loss: 0.12484949827194214\n",
            "Epoch: 42, Loss: 0.12231612205505371\n",
            "Epoch: 43, Loss: 0.1198345497250557\n",
            "Epoch: 44, Loss: 0.11740367859601974\n",
            "Epoch: 45, Loss: 0.11502249538898468\n",
            "Epoch: 46, Loss: 0.11268998682498932\n",
            "Epoch: 47, Loss: 0.11040515452623367\n",
            "Epoch: 48, Loss: 0.10816700756549835\n",
            "Epoch: 49, Loss: 0.10597460716962814\n",
            "Epoch: 50, Loss: 0.10382699966430664\n",
            "Epoch: 51, Loss: 0.10172329097986221\n",
            "Epoch: 52, Loss: 0.09966257214546204\n",
            "Epoch: 53, Loss: 0.09764397144317627\n",
            "Epoch: 54, Loss: 0.09566660225391388\n",
            "Epoch: 55, Loss: 0.093729667365551\n",
            "Epoch: 56, Loss: 0.09183228760957718\n",
            "Epoch: 57, Loss: 0.08997370302677155\n",
            "Epoch: 58, Loss: 0.08815306425094604\n",
            "Epoch: 59, Loss: 0.08636964112520218\n",
            "Epoch: 60, Loss: 0.08462263643741608\n",
            "Epoch: 61, Loss: 0.08291134238243103\n",
            "Epoch: 62, Loss: 0.08123499900102615\n",
            "Epoch: 63, Loss: 0.07959292829036713\n",
            "Epoch: 64, Loss: 0.07798438519239426\n",
            "Epoch: 65, Loss: 0.07640870660543442\n",
            "Epoch: 66, Loss: 0.07486522197723389\n",
            "Epoch: 67, Loss: 0.07335326075553894\n",
            "Epoch: 68, Loss: 0.07187219709157944\n",
            "Epoch: 69, Loss: 0.07042136788368225\n",
            "Epoch: 70, Loss: 0.06900018453598022\n",
            "Epoch: 71, Loss: 0.06760801374912262\n",
            "Epoch: 72, Loss: 0.06624431163072586\n",
            "Epoch: 73, Loss: 0.06490843743085861\n",
            "Epoch: 74, Loss: 0.0635998472571373\n",
            "Epoch: 75, Loss: 0.06231798231601715\n",
            "Epoch: 76, Loss: 0.061062298715114594\n",
            "Epoch: 77, Loss: 0.05983225628733635\n",
            "Epoch: 78, Loss: 0.05862732604146004\n",
            "Epoch: 79, Loss: 0.057447001338005066\n",
            "Epoch: 80, Loss: 0.056290775537490845\n",
            "Epoch: 81, Loss: 0.05515816807746887\n",
            "Epoch: 82, Loss: 0.054048679769039154\n",
            "Epoch: 83, Loss: 0.052961837500333786\n",
            "Epoch: 84, Loss: 0.051897190511226654\n",
            "Epoch: 85, Loss: 0.05085426941514015\n",
            "Epoch: 86, Loss: 0.049832649528980255\n",
            "Epoch: 87, Loss: 0.04883188009262085\n",
            "Epoch: 88, Loss: 0.04785153269767761\n",
            "Epoch: 89, Loss: 0.04689120128750801\n",
            "Epoch: 90, Loss: 0.045950472354888916\n",
            "Epoch: 91, Loss: 0.045028943568468094\n",
            "Epoch: 92, Loss: 0.04412621259689331\n",
            "Epoch: 93, Loss: 0.04324190691113472\n",
            "Epoch: 94, Loss: 0.042375657707452774\n",
            "Epoch: 95, Loss: 0.041527070105075836\n",
            "Epoch: 96, Loss: 0.040695805102586746\n",
            "Epoch: 97, Loss: 0.03988150879740715\n",
            "Epoch: 98, Loss: 0.0390838161110878\n",
            "Epoch: 99, Loss: 0.038302402943372726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without manual weights and forward"
      ],
      "metadata": {
        "id": "5gkVHfSQghBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=nn.Linear(3,3)"
      ],
      "metadata": {
        "id": "raFhhhuGeaIr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=100\n",
        "lr=0.01\n",
        "loss= nn.MSELoss()\n",
        "optimizer= torch.optim.SGD(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "mcOxKm0zmIg6"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  y_pred=model(X)\n",
        "  l=loss(Y,y_pred)\n",
        "  l.backward()\n",
        "  optimizer.step() #automatic update weights\n",
        "  optimizer.zero_grad()\n",
        "  print(f\"Epoch: {epoch}, Loss: {l}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJTM1A-pmjO_",
        "outputId": "d859afd1-a9eb-42c6-95ed-b4a53aa324ba"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.40170636773109436\n",
            "Epoch: 1, Loss: 0.3939256966114044\n",
            "Epoch: 2, Loss: 0.38630053400993347\n",
            "Epoch: 3, Loss: 0.3788280487060547\n",
            "Epoch: 4, Loss: 0.37150493264198303\n",
            "Epoch: 5, Loss: 0.3643285036087036\n",
            "Epoch: 6, Loss: 0.35729551315307617\n",
            "Epoch: 7, Loss: 0.35040321946144104\n",
            "Epoch: 8, Loss: 0.34364888072013855\n",
            "Epoch: 9, Loss: 0.3370295763015747\n",
            "Epoch: 10, Loss: 0.3305427134037018\n",
            "Epoch: 11, Loss: 0.3241855204105377\n",
            "Epoch: 12, Loss: 0.31795555353164673\n",
            "Epoch: 13, Loss: 0.3118501305580139\n",
            "Epoch: 14, Loss: 0.3058668375015259\n",
            "Epoch: 15, Loss: 0.30000320076942444\n",
            "Epoch: 16, Loss: 0.2942568361759186\n",
            "Epoch: 17, Loss: 0.2886253297328949\n",
            "Epoch: 18, Loss: 0.2831064760684967\n",
            "Epoch: 19, Loss: 0.27769798040390015\n",
            "Epoch: 20, Loss: 0.27239760756492615\n",
            "Epoch: 21, Loss: 0.267203152179718\n",
            "Epoch: 22, Loss: 0.2621126174926758\n",
            "Epoch: 23, Loss: 0.25712379813194275\n",
            "Epoch: 24, Loss: 0.2522347867488861\n",
            "Epoch: 25, Loss: 0.24744343757629395\n",
            "Epoch: 26, Loss: 0.24274788796901703\n",
            "Epoch: 27, Loss: 0.23814617097377777\n",
            "Epoch: 28, Loss: 0.23363642394542694\n",
            "Epoch: 29, Loss: 0.22921685874462128\n",
            "Epoch: 30, Loss: 0.22488552331924438\n",
            "Epoch: 31, Loss: 0.22064079344272614\n",
            "Epoch: 32, Loss: 0.21648089587688446\n",
            "Epoch: 33, Loss: 0.21240411698818207\n",
            "Epoch: 34, Loss: 0.20840877294540405\n",
            "Epoch: 35, Loss: 0.20449328422546387\n",
            "Epoch: 36, Loss: 0.200655996799469\n",
            "Epoch: 37, Loss: 0.19689534604549408\n",
            "Epoch: 38, Loss: 0.19320984184741974\n",
            "Epoch: 39, Loss: 0.189597949385643\n",
            "Epoch: 40, Loss: 0.1860581785440445\n",
            "Epoch: 41, Loss: 0.1825891137123108\n",
            "Epoch: 42, Loss: 0.17918933928012848\n",
            "Epoch: 43, Loss: 0.17585743963718414\n",
            "Epoch: 44, Loss: 0.17259210348129272\n",
            "Epoch: 45, Loss: 0.1693919450044632\n",
            "Epoch: 46, Loss: 0.1662556380033493\n",
            "Epoch: 47, Loss: 0.16318197548389435\n",
            "Epoch: 48, Loss: 0.16016969084739685\n",
            "Epoch: 49, Loss: 0.15721751749515533\n",
            "Epoch: 50, Loss: 0.1543242633342743\n",
            "Epoch: 51, Loss: 0.1514887511730194\n",
            "Epoch: 52, Loss: 0.14870980381965637\n",
            "Epoch: 53, Loss: 0.14598633348941803\n",
            "Epoch: 54, Loss: 0.14331717789173126\n",
            "Epoch: 55, Loss: 0.1407013088464737\n",
            "Epoch: 56, Loss: 0.1381375789642334\n",
            "Epoch: 57, Loss: 0.13562503457069397\n",
            "Epoch: 58, Loss: 0.13316258788108826\n",
            "Epoch: 59, Loss: 0.13074924051761627\n",
            "Epoch: 60, Loss: 0.1283840388059616\n",
            "Epoch: 61, Loss: 0.12606598436832428\n",
            "Epoch: 62, Loss: 0.12379414588212967\n",
            "Epoch: 63, Loss: 0.12156760692596436\n",
            "Epoch: 64, Loss: 0.11938545107841492\n",
            "Epoch: 65, Loss: 0.11724679917097092\n",
            "Epoch: 66, Loss: 0.11515074968338013\n",
            "Epoch: 67, Loss: 0.11309648305177689\n",
            "Epoch: 68, Loss: 0.11108314990997314\n",
            "Epoch: 69, Loss: 0.10910991579294205\n",
            "Epoch: 70, Loss: 0.10717601329088211\n",
            "Epoch: 71, Loss: 0.10528060793876648\n",
            "Epoch: 72, Loss: 0.10342296957969666\n",
            "Epoch: 73, Loss: 0.10160232335329056\n",
            "Epoch: 74, Loss: 0.0998179093003273\n",
            "Epoch: 75, Loss: 0.09806906431913376\n",
            "Epoch: 76, Loss: 0.09635499864816666\n",
            "Epoch: 77, Loss: 0.09467506408691406\n",
            "Epoch: 78, Loss: 0.09302855283021927\n",
            "Epoch: 79, Loss: 0.09141480177640915\n",
            "Epoch: 80, Loss: 0.08983317017555237\n",
            "Epoch: 81, Loss: 0.0882829949259758\n",
            "Epoch: 82, Loss: 0.08676367253065109\n",
            "Epoch: 83, Loss: 0.08527453988790512\n",
            "Epoch: 84, Loss: 0.08381503820419312\n",
            "Epoch: 85, Loss: 0.08238454908132553\n",
            "Epoch: 86, Loss: 0.08098248392343521\n",
            "Epoch: 87, Loss: 0.07960829883813858\n",
            "Epoch: 88, Loss: 0.07826141268014908\n",
            "Epoch: 89, Loss: 0.07694130390882492\n",
            "Epoch: 90, Loss: 0.07564741373062134\n",
            "Epoch: 91, Loss: 0.07437922060489655\n",
            "Epoch: 92, Loss: 0.07313621044158936\n",
            "Epoch: 93, Loss: 0.07191788405179977\n",
            "Epoch: 94, Loss: 0.0707237496972084\n",
            "Epoch: 95, Loss: 0.06955330818891525\n",
            "Epoch: 96, Loss: 0.06840609759092331\n",
            "Epoch: 97, Loss: 0.06728164851665497\n",
            "Epoch: 98, Loss: 0.06617950648069382\n",
            "Epoch: 99, Loss: 0.06509923189878464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([2, 3])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBnM4cBZmmKV",
        "outputId": "83157bc2-9ad8-4a0a-93f5-7f867e36cd2a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=3, out_features=3, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BNVkEpdympq-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}